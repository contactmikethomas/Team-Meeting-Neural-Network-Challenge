{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Neural Network Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is somewhat similiar to the classic MNIST number classificaiton project, but with a larger and potentially more interesting dataset. Details here: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Citation: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n",
    "\n",
    "We will be using Keras to build a convolutional neural network and predict house numbers from pictures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Reading in MATLAB files\n",
    "import scipy.io \n",
    "\n",
    "# Preparing the Data\n",
    "import numpy as np \n",
    "from PIL import ImageOps, Image # Equalise the image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Building and Testing the Network\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input = scipy.io.loadmat('train_32x32.mat')\n",
    "\n",
    "#Process Image Data\n",
    "def process_image(image_array):\n",
    "    \n",
    "    img_in = Image.fromarray(image_array)\n",
    "    img_equalised = ImageOps.equalize(img_in, mask=None)\n",
    "    img_final = np.array(img_equalised, dtype=np.float32)\n",
    "    \n",
    "    return img_final\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for i in range(73257):\n",
    "    new_image = []\n",
    "    for j in range(32):\n",
    "        new_row = []\n",
    "        for k in range(32):\n",
    "            new_row.append([training_input['X'][j][k][0][i], training_input['X'][j][k][1][i], training_input['X'][j][k][2][i]])\n",
    "        new_image.append(new_row)        \n",
    "    all_images.append(process_image(np.asarray(new_image))/255)\n",
    "    \n",
    "all_images_array = np.asarray(all_images)\n",
    "\n",
    "#Process Tags\n",
    "all_tags = []\n",
    "for i in range(73257):\n",
    "    all_tags.append(training_input['y'][i][0])\n",
    "\n",
    "all_tags_array = np.asarray(all_tags)\n",
    "\n",
    "# Label encoding tags\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(all_tags_array.reshape(-1))\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# One hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images_array, onehot_encoded, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (58605, 32, 32, 3)\n",
      "y_train shape: (58605, 10)\n",
      "58605 Training samples\n",
      "14652 Testing samples\n"
     ]
    }
   ],
   "source": [
    "#This code is largely borrowed from Keras' MNIST example.\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "x_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'Training samples')\n",
    "print(x_test.shape[0], 'Testing samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58605 samples, validate on 14652 samples\n",
      "Epoch 1/2\n",
      "58605/58605 [==============================] - 32s 543us/step - loss: 1.8995 - acc: 0.3714 - val_loss: 1.7453 - val_acc: 0.4211\n",
      "Epoch 2/2\n",
      "58605/58605 [==============================] - 32s 540us/step - loss: 1.6696 - acc: 0.4612 - val_loss: 1.7080 - val_acc: 0.4421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6e84bb67f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test data:\n",
      "Test loss: 1.7080498358085772\n",
      "Test accuracy: 0.4421239421320782\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test data:\")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
